GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/glade/u/home/piyushag/.conda/envs/pa2/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /glade/work/piyushag/cmex_ml0/NN_IOdata_ckpts_Jul26onwards/tckpts exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
Restoring states from the checkpoint path at last2
Traceback (most recent call last):
  File "/glade/u/home/piyushag/.conda/envs/pa2/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/glade/u/home/piyushag/.conda/envs/pa2/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/glade/work/piyushag/cmex_ml0/codes/pca1.py", line 139, in <module>
    trainer.fit(model, data_loader, ckpt_path='last2')
  File "/glade/u/home/piyushag/.conda/envs/pa2/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 608, in fit
    call._call_and_handle_interrupt(
  File "/glade/u/home/piyushag/.conda/envs/pa2/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 38, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/glade/u/home/piyushag/.conda/envs/pa2/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _fit_impl
    self._run(model, ckpt_path=self.ckpt_path)
  File "/glade/u/home/piyushag/.conda/envs/pa2/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1056, in _run
    self._restore_modules_and_callbacks(ckpt_path)
  File "/glade/u/home/piyushag/.conda/envs/pa2/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 998, in _restore_modules_and_callbacks
    self._checkpoint_connector.resume_start(checkpoint_path)
  File "/glade/u/home/piyushag/.conda/envs/pa2/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 90, in resume_start
    loaded_checkpoint = self.trainer.strategy.load_checkpoint(checkpoint_path)
  File "/glade/u/home/piyushag/.conda/envs/pa2/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 359, in load_checkpoint
    return self.checkpoint_io.load_checkpoint(checkpoint_path)
  File "/glade/u/home/piyushag/.conda/envs/pa2/lib/python3.9/site-packages/lightning_fabric/plugins/io/torch_io.py", line 84, in load_checkpoint
    raise FileNotFoundError(f"Checkpoint at {path} not found. Aborting training.")
FileNotFoundError: Checkpoint at last2 not found. Aborting training.
Traceback (most recent call last):
  File "/glade/u/home/piyushag/.conda/envs/pa2/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/glade/u/home/piyushag/.conda/envs/pa2/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/glade/work/piyushag/cmex_ml0/codes/pca1.py", line 139, in <module>
    trainer.fit(model, data_loader, ckpt_path='last2')
  File "/glade/u/home/piyushag/.conda/envs/pa2/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 608, in fit
    call._call_and_handle_interrupt(
  File "/glade/u/home/piyushag/.conda/envs/pa2/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 38, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/glade/u/home/piyushag/.conda/envs/pa2/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _fit_impl
    self._run(model, ckpt_path=self.ckpt_path)
  File "/glade/u/home/piyushag/.conda/envs/pa2/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1056, in _run
    self._restore_modules_and_callbacks(ckpt_path)
  File "/glade/u/home/piyushag/.conda/envs/pa2/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 998, in _restore_modules_and_callbacks
    self._checkpoint_connector.resume_start(checkpoint_path)
  File "/glade/u/home/piyushag/.conda/envs/pa2/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 90, in resume_start
    loaded_checkpoint = self.trainer.strategy.load_checkpoint(checkpoint_path)
  File "/glade/u/home/piyushag/.conda/envs/pa2/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 359, in load_checkpoint
    return self.checkpoint_io.load_checkpoint(checkpoint_path)
  File "/glade/u/home/piyushag/.conda/envs/pa2/lib/python3.9/site-packages/lightning_fabric/plugins/io/torch_io.py", line 84, in load_checkpoint
    raise FileNotFoundError(f"Checkpoint at {path} not found. Aborting training.")
FileNotFoundError: Checkpoint at last2 not found. Aborting training.